{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_GuW8UbIQKUC"
      },
      "source": [
        "**Import necessary modules**\n",
        "nn and optim for neural network construction and optimizers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sNPpMS16QKUE"
      },
      "outputs": [],
      "source": [
        "import torch, cv2, os, random, json, time, sys\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torch.optim.lr_scheduler import _LRScheduler\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LSpcgOxEQKUF",
        "outputId": "c9c8ebd7-d7fc-4aa2-a94f-662338f1ff81"
      },
      "outputs": [],
      "source": [
        "# This is a test for the imported torch library\n",
        "\n",
        "# Assume input feature map with dimensions [batch_size, channels, height, width]\n",
        "input_feature_map = torch.randn(1, 5, 5)  # Example input\n",
        "\n",
        "# Define global average pooling operation\n",
        "global_avg_pool = nn.AdaptiveAvgPool2d(1)\n",
        "global_max_pool = nn.AdaptiveMaxPool2d(1)\n",
        "convolution = nn.Conv2d(3, 5, 3)\n",
        "\n",
        "# Apply global average pooling to input\n",
        "map = global_max_pool(input_feature_map)\n",
        "\n",
        "print(map.shape)\n",
        "print(input_feature_map)\n",
        "print(map)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iKk8vv4UQKUG"
      },
      "source": [
        "# Model Architecture\n",
        "* Individual Components:\n",
        "    * CBAM Module\n",
        "    * Channel Attention\n",
        "    * Spatial Attention\n",
        "    * DCNN (Deep Convolutional Neural Network)\n",
        "\n",
        "Convolutional Block Attention Module:\n",
        "This allows the neural network to focus on specific aspects of the image and improves\n",
        "the representation of interests. If, for example, the input feature map tensor dimensions\n",
        "are 6 x 127 x 127, the output will have the same dimensions. The CBAM module works on each feature map and enhances certain aspects of each feature map.\n",
        "\n",
        "# Proposed Architecture for this task:\n",
        "**Channel Attention**\n",
        "\n",
        "\n",
        "**Spatial Attention**\n",
        "\n",
        "\n",
        "**CBAM (Convolutional Block Attention Module)**\n",
        "\n",
        "\n",
        "**CNN Feature Extracion**\n",
        "Input (512 x 512) ->\n",
        "\n",
        "6 x (Conv2d -> CBAM -> PReLU -> Conv2d -> CBAM -> PReLU -> MaxPool) ->\n",
        "\n",
        "Flatten the feature maps to serve as inputs to DNN (5880 inputs) ->\n",
        "DNN (output 4)\n",
        "\n",
        "**DNN Classification**\n",
        "L1 (5880) ->\n",
        "ReLU ->\n",
        "L2 (1024) ->\n",
        "ReLU ->\n",
        "L3 (512) ->\n",
        "ReLU ->\n",
        "L4 (256) ->\n",
        "ReLU ->\n",
        "L5 (128) ->\n",
        "ReLU ->\n",
        "L6 (64) ->\n",
        "ReLU ->\n",
        "L7 (32) ->\n",
        "ReLU ->\n",
        "L8 (4) ->\n",
        "Softmax ->\n",
        "\n",
        "Output: Classification probabilities (4 x 1)\n",
        "\n",
        "# Notes\n",
        "There are two architectures for this task. Both of them are almost the same but one does not use the attention mechanism. This provides a baseline to determine if the attention mechanism is effective."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S3iQykfuQKUG"
      },
      "outputs": [],
      "source": [
        "class channel_attention(nn.Module):\n",
        "    def __init__(self, in_channels, reduction_ratio=4):\n",
        "        super(channel_attention, self).__init__()\n",
        "\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.max_pool = nn.AdaptiveMaxPool2d(1)\n",
        "\n",
        "        # We can use Conv2d instead of FCLs to simplify the operation and avoid having to flatten the layers.\n",
        "        # The operation is essentially the same as in the CBAM paper but applied in a different way.\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, math.ceil(in_channels / reduction_ratio), 1, bias=False),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(math.ceil(in_channels / reduction_ratio), in_channels, 1, bias=False)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # As the network is trained, the channels (feature maps) that should be paid more attention to become more pronounced.\n",
        "        # Example avg_o and max_o ==> input: [batch_size, 6, 512, 512] -> 2 x [batch_size, 6, 1, 1] -> 2 x [batch_size, 2, 1, 1] -> 2 x [batch_size, 6, 1, 1]\n",
        "        avg_o = self.fc(self.avg_pool(x))\n",
        "        max_o = self.fc(self.max_pool(x))\n",
        "        # Here just add the two channel attentions and put it through a sigmoid function.\n",
        "        # This will give the attention score for each channel.\n",
        "        out = torch.sigmoid(avg_o + max_o)\n",
        "        return out\n",
        "\n",
        "\n",
        "class spatial_attention(nn.Module):\n",
        "    def __init__(self, kernel_size=7):\n",
        "        super(spatial_attention, self).__init__()\n",
        "        self.conv = nn.Conv2d(2, 1, kernel_size, padding=kernel_size//2, bias=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        # Compress across the channel dimension by getting the average and max of all values across that dimension.\n",
        "        # input: (batch_size, #channels, height, width) -> output: (batch_size, 1, height, width)\n",
        "        avg_map = torch.mean(x, dim=1, keepdim=True)\n",
        "        max_map, thr = torch.max(x, dim=1, keepdim=True)\n",
        "\n",
        "        # Concat the two maps.\n",
        "        # input: 2 x (batch_size, 1, height, width) -> output: (batch_size, 2, height, width)\n",
        "        x = torch.cat([avg_map, max_map], dim=1)\n",
        "\n",
        "        x = self.conv(x)\n",
        "        out = torch.sigmoid(x)\n",
        "        return out\n",
        "\n",
        "class CBAM(nn.Module):\n",
        "    def __init__(self, in_channels, reduction_ratio=4,sa_kernel_size=7):\n",
        "        super(CBAM, self).__init__()\n",
        "        self.channel = channel_attention(in_channels, reduction_ratio)\n",
        "        self.spatial = spatial_attention(sa_kernel_size)\n",
        "    def forward(self, x):\n",
        "        x = x * self.channel(x)\n",
        "        x = x * self.spatial(x)\n",
        "        return x\n",
        "\n",
        "class CNN_Attention(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN_Attention, self).__init__()\n",
        "        self.block1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=1, out_channels=6, kernel_size=3),\n",
        "            nn.BatchNorm2d(6),\n",
        "            CBAM(6),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "        )\n",
        "        self.block2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=6, out_channels=12, kernel_size=3),\n",
        "            nn.BatchNorm2d(12),\n",
        "            CBAM(12),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "        )\n",
        "        self.block3 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=12, out_channels=24, kernel_size=3),\n",
        "            nn.BatchNorm2d(24),\n",
        "            CBAM(24),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "        )\n",
        "        self.block4 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=24, out_channels=48, kernel_size=3),\n",
        "            nn.BatchNorm2d(48),\n",
        "            CBAM(48),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "        )\n",
        "        self.block5 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=48, out_channels=96, kernel_size=3),\n",
        "            nn.BatchNorm2d(96),\n",
        "            CBAM(96),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "        )\n",
        "        self.block6 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=96, out_channels=192, kernel_size=3),\n",
        "            nn.BatchNorm2d(192),\n",
        "            CBAM(192),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        x = self.block1(x)\n",
        "        x = self.block2(x)\n",
        "        x = self.block3(x)\n",
        "        x = self.block4(x)\n",
        "        x = self.block5(x)\n",
        "        return x\n",
        "\n",
        "# CNN without CBAM\n",
        "class CNN_NoAttention(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN_NoAttention, self).__init__()\n",
        "        self.block1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=1, out_channels=6, kernel_size=3),\n",
        "            nn.BatchNorm2d(6),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "        )\n",
        "        self.block2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=6, out_channels=12, kernel_size=3),\n",
        "            nn.BatchNorm2d(12),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "        )\n",
        "        self.block3 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=12, out_channels=24, kernel_size=3),\n",
        "            nn.BatchNorm2d(24),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "        )\n",
        "        self.block4 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=24, out_channels=48, kernel_size=3),\n",
        "            nn.BatchNorm2d(48),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "        )\n",
        "        self.block5 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=48, out_channels=96, kernel_size=3),\n",
        "            nn.BatchNorm2d(96),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "        )\n",
        "        self.block6 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=96, out_channels=192, kernel_size=3),\n",
        "            nn.BatchNorm2d(192),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        x = self.block1(x)\n",
        "        x = self.block2(x)\n",
        "        x = self.block3(x)\n",
        "        x = self.block4(x)\n",
        "        x = self.block5(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class DNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(DNN, self).__init__()\n",
        "        self.classify = nn.Sequential(\n",
        "            nn.Linear(18816, 2048),\n",
        "            nn.BatchNorm1d(2048),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(2048, 1024),\n",
        "            nn.BatchNorm1d(1024),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.BatchNorm1d(512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.BatchNorm1d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 32),\n",
        "            nn.BatchNorm1d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(32, 4)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.classify(x)\n",
        "\n",
        "class BrainTumorClassifier_Attention(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(BrainTumorClassifier_Attention, self).__init__()\n",
        "        self.feature_extraction = CNN_Attention()\n",
        "        self.classification = DNN()\n",
        "    def forward(self, x):\n",
        "        features = self.feature_extraction(x)\n",
        "        flattened_features = features.view(features.size(0), -1)\n",
        "        classification = self.classification(flattened_features)\n",
        "        return classification\n",
        "\n",
        "class BrainTumorClassifier_NoAttention(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(BrainTumorClassifier_NoAttention, self).__init__()\n",
        "        self.feature_extraction = CNN_NoAttention()\n",
        "        self.classification = DNN()\n",
        "    def forward(self, x):\n",
        "        features = self.feature_extraction(x)\n",
        "        flattened_features = features.view(features.size(0), -1)\n",
        "        classification = self.classification(flattened_features)\n",
        "        return classification\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "attention_select = input(\"Use attention for classification? (Y|N)\")\n",
        "model = None\n",
        "if (attention_select == \"Y\"):\n",
        "    model = BrainTumorClassifier_Attention()\n",
        "else:\n",
        "    model = BrainTumorClassifier_NoAttention()\n",
        "model.to(torch.float32)\n",
        "\n",
        "device = torch.device(\"cpu\")\n",
        "if torch.cuda.is_available:\n",
        "    torch.cuda.empty_cache()\n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "dvc = next(model.parameters()).device\n",
        "print(\"Model is on device:\", dvc)\n",
        "\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "\n",
        "print(f\"Total number of parameters: {total_params}\")\n",
        "\n",
        "num_parameters = 6736274\n",
        "size_of_float32 = 4  # 4 bytes for float32\n",
        "total_memory_bytes = num_parameters * size_of_float32\n",
        "total_memory_mb = (total_memory_bytes / (2**20))\n",
        "\n",
        "print(f\"Total estimated memory usage: {total_memory_mb:.2f} MB\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ImageDataset(Dataset):\n",
        "    def __init__(self, IO_pairs):\n",
        "        self.IO_pairs = IO_pairs\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.IO_pairs)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # Get the image\n",
        "        image_class_name = self.IO_pairs[index][0]\n",
        "        image_tensor_list = self.IO_pairs[index][1]\n",
        "        classification_target = self.IO_pairs[index][2]\n",
        "\n",
        "        return image_class_name, image_tensor_list, classification_target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "num_epochs = 20\n",
        "\n",
        "pt_path = \"./content/train/train_datasets/train_dataset1.pt\"\n",
        "dataset = torch.load(pt_path)\n",
        "dataloader = DataLoader(dataset, batch_size=10, shuffle=True)\n",
        "model.train()\n",
        "\n",
        "class_loss_function = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.03)\n",
        "#scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=2, eta_min=0.00001)\n",
        "scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.95)\n",
        "\n",
        "correction_threshold = 0.4\n",
        "max_repetitions = 10\n",
        "\n",
        "supervise = input(\"Enable constant supervision? (Y|N)\")\n",
        "superv_bool = False\n",
        "if (supervise == \"Y\"):\n",
        "    superv_bool = True\n",
        "else:\n",
        "    superv_bool = False\n",
        "\n",
        "sum_class_loss = 0\n",
        "total_backwards = 0\n",
        "previous_avg_loss = 0\n",
        "\n",
        "contin = \"Y\"\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "    for i, j in enumerate(dataloader):\n",
        "        \n",
        "        image_class_name = j[0]\n",
        "        image_tensor = j[1]\n",
        "        image_class_tensor = j[2]\n",
        "\n",
        "        image_tensor = image_tensor.to(torch.float32)\n",
        "        image_class_tensor = image_class_tensor.to(torch.float32)\n",
        "\n",
        "        image_tensor = image_tensor.to(device)\n",
        "        image_class_tensor = image_class_tensor.to(device)\n",
        "            \n",
        "        optimizer.zero_grad()\n",
        "        prediction = model(image_tensor)\n",
        "        classification_loss = class_loss_function(prediction, image_class_tensor)\n",
        "        classification_loss.backward()\n",
        "        optimizer.step()\n",
        "        sum_class_loss += round(classification_loss.item(), 5)\n",
        "        total_backwards += 1\n",
        "\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}], Progress: [{i+1}/{len(dataloader)}], Class_Loss: {round(classification_loss.item(), 5)}, Learning Rate: {scheduler.get_last_lr()[0]}, Previous Loss: {previous_avg_loss}\")\n",
        "\n",
        "        # Reduce memory to device time overhead\n",
        "        if (round(classification_loss.item(), 5) > previous_avg_loss or round(classification_loss.item(), 5) > 0.35) and epoch + 1 >= 2:\n",
        "            for m in range(min(math.ceil(epoch), max_repetitions)):\n",
        "                optimizer.zero_grad()\n",
        "                prediction = model(image_tensor)\n",
        "                classification_loss = class_loss_function(prediction, image_class_tensor)\n",
        "                classification_loss.backward()\n",
        "                optimizer.step()\n",
        "                sum_class_loss += round(classification_loss.item(), 5)\n",
        "                total_backwards += 1\n",
        "\n",
        "                print(f\"Epoch [{epoch+1}/{num_epochs}], Progress: [{i+1}/{len(dataloader)}, T{m}], Class_Loss: {round(classification_loss.item(), 5)}, Learning Rate: {scheduler.get_last_lr()[0]}, Previous Loss: {previous_avg_loss}\")\n",
        "    \n",
        "    previous_avg_loss = round(sum_class_loss / total_backwards, 5)\n",
        "    sum_class_loss = 0\n",
        "    total_backwards = 0\n",
        "    \n",
        "    if ((epoch + 1) % 4 == 0):\n",
        "        if (superv_bool):\n",
        "            contin = input(\"Continue for 4 more epochs? (Y|N)\")\n",
        "            if (contin == \"N\"):\n",
        "                break\n",
        "            else:\n",
        "                pass\n",
        "        scheduler.step()\n",
        "    \n",
        "    if (contin == \"N\"):\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if not os.path.exists(\"./content/models\"):\n",
        "    os.mkdir(\"./content/models\")\n",
        "mytext = input(\"Enter the model name: \")\n",
        "torch.save(model, f\"./content/models/{mytext}.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "eval_select = input(\"Which model do you want to evaluate?\")\n",
        "attention_select = input(\"Attention? (Y|N)\")\n",
        "\n",
        "if (attention_select == \"Y\"):\n",
        "    loaded_model: BrainTumorClassifier_Attention = torch.load(f\"./content/models/{eval_select}.pt\")\n",
        "else:\n",
        "    loaded_model: BrainTumorClassifier_NoAttention = torch.load(f\"./content/models/{eval_select}.pt\")\n",
        "\n",
        "loaded_model.to(torch.float32)\n",
        "loaded_model.to(device)\n",
        "loaded_model.eval()\n",
        "\n",
        "test_set = torch.load(\"./content/test/test_datasets/test_dataset1.pt\")\n",
        "train_set = torch.load(\"./content/train/train_datasets/train_dataset1.pt\")\n",
        "\n",
        "test_correct = 0\n",
        "test_tested = 0\n",
        "\n",
        "for i in range(test_set.__len__()):\n",
        "\n",
        "    current_eval = test_set.__getitem__(i)\n",
        "    inputTensor = current_eval[1]\n",
        "    inputTensor = inputTensor.to(torch.float32)\n",
        "    inputTensor = inputTensor.to(device)\n",
        "    inputTensor = inputTensor.unsqueeze(0)\n",
        "    \n",
        "    target = current_eval[2]\n",
        "    predicted_output = loaded_model(inputTensor)\n",
        "    if (predicted_output.argmax() == target.argmax()):\n",
        "        test_correct += 1\n",
        "    test_tested += 1\n",
        "\n",
        "    print(\"Testing Eval: \" + str(test_correct / test_tested))\n",
        "\n",
        "train_correct = 0\n",
        "train_tested = 0\n",
        "\n",
        "for i in range(train_set.__len__()):\n",
        "\n",
        "    current_eval = train_set.__getitem__(i)\n",
        "    inputTensor = current_eval[1]\n",
        "    inputTensor = inputTensor.to(torch.float32)\n",
        "    inputTensor = inputTensor.to(device)\n",
        "    inputTensor = inputTensor.unsqueeze(0)\n",
        "    \n",
        "    target = current_eval[2]\n",
        "    predicted_output = loaded_model(inputTensor)\n",
        "    if (predicted_output.argmax() == target.argmax()):\n",
        "        train_correct += 1\n",
        "    train_tested += 1\n",
        "\n",
        "    print(\"Training Eval: \" + str(train_correct / train_tested))\n",
        "\n",
        "\n",
        "print(\"\\n\\nOverall Results: \")\n",
        "print(\"Testing Eval: \" + str(test_correct / test_tested))\n",
        "print(\"Training Eval: \" + str(train_correct / train_tested))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
